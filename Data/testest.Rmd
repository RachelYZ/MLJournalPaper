---
title: "R Notebook"
output:
  pdf_document: default
  html_notebook: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE,
                      out.height = "\\textheight",  out.width = "\\textwidth")
library(kableExtra)
library(tidyverse)
library(dplyr)
library(reshape2)
library(stargazer)
library(colorspace)
library(ggplot2)
library(texreg) 
library(caret)
library(rpart)
library(e1071)
library(forecast)
library(neuralnet)
library(kknn)
library(dummies)
options(digits = 3)
setwd("~/Documents/Research/MLJournalPaper/Data")
```

```{r functions, include=FALSE}
convert_date = function(x){ #to convert date
  require(dplyr)
  new = as.Date(x, '%y.%m.%d') %>%
     format(., '20%y-%m-%d') %>%
    as.Date()
  return (new)
}

materr = function(data){  
  require(dplyr)
  m = data 
  for (j in 2:ncol(data)){
    m[,j] = (data[,j] - data[,1]) #calculating errors for each forecast
  }
  ME = colMeans(m)
  MAE = colMeans(abs(m))
  SD = apply(m,2,sd)
  p = data
  for (i in 2:ncol(p)){
    p[, i] = m[,i] / data[,1]
  }
  MPE = colMeans(p)
  MAPE = colMeans(abs(p))
  return(rbind(ME,MAE,MPE,MAPE,SD))
} 
```

# 1 

```{r loaddata}
dt <- read.csv("~/Documents/Research/Thesis writing/NewData/Arr.csv") %>% 
  data.frame()%>%
  select(Arrival.Date, Booking.Window, Quantity) %>%
  mutate_at(., vars(Arrival.Date),  funs(as.Date(., "%m/%d/%Y"))) %>%
  group_by(Arrival.Date, Booking.Window) %>%
  mutate(Quan = sum(Quantity)) %>%
  dplyr::arrange(., Arrival.Date, Booking.Window, Quan) 
dt = dt[-(1:2),-3] 
dt$Arrival.Date = convert_date(dt$Arrival.Date)
#---same----# 

wide = dcast(dt, Arrival.Date ~ Booking.Window, value.var='Quan') %>% 
  data.frame() %>%
  arrange(., Arrival.Date)

for (i in (ncol(wide)-1):2){
  wide[i] = wide[i] + wide[i+1] 
}

agg = c(1, 2, 3, 4, 5, 6, 7, 14, 21, 30, 60, 90)
wide = wide %>%
  mutate(DOW = weekdays(Arrival.Date)) %>%
  remove_rownames %>% column_to_rownames('Arrival.Date') %>%
  select(X0, DOW, paste0("X",agg)) 
colnames(wide) = c('ROH0', 'DOW', paste0('ROH',agg))
wide$DOW <- ordered(wide$DOW, levels=c("Sunday","Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))
```

```{r cv}
set.seed(0)
tr_ind = sample(nrow(wide), 0.8*nrow(wide))
train = wide[tr_ind, ]
test = wide[-tr_ind, ]
```

There are `r nrow(train)` trasactions with DBA up to 90 days. 
### Regression 

```{r reg}
reg.pred = test
reg.pred[,3:ncol(reg.pred)] = NA
reg = vector(mode='list')
train$DOW = factor(train$DOW , ordered = FALSE )
s1 = Sys.time()
for (i in agg){ 
  this.predictor = paste0(paste0('ROH',agg[which(agg==i)]), collapse='+')
  lm.formula = paste('ROH0', paste0('DOW+', this.predictor), sep = '~')
  reg[[this.predictor]] = lm(lm.formula, data = train)
  reg.pred[, which(names(reg.pred)==paste0('ROH',i))]=predict(reg[[this.predictor]], test)
}
time.reg = Sys.time() - s1
reg.err = t(materr(reg.pred[,-2])) %>% data.frame() 
#stargazer(reg[1], reg[2], title='Regression Results', align=TRUE)
#texreg(reg, booktabs = TRUE, dcolumn=TRUE)
texreg(list(reg[[1]], reg[[2]], reg[[3]], reg[[4]], reg[[5]], reg[[6]], reg[[7]], reg[[8]],reg[[9]],reg[[10]],reg[[11]],reg[[12]]))
```

\newpage
\landscape
```{r echo=FALSE, results = "asis"}
texreg(list(reg[[1]], reg[[2]], reg[[3]], reg[[4]], reg[[5]], reg[[6]], reg[[7]], reg[[8]],reg[[9]],reg[[10]],reg[[11]],reg[[12]]))
```


```{r eval=FALSE}
set.seed(0)
nn.train.scaled=scale(train[,-2]) #standardization
nn.test.scaled= scale(test[,-2]) 
dow.tr = dummy(train$DOW, sep='.')
dow.te = dummy(test$DOW, sep='.')
nn.train.scaled = data.frame(cbind(dow.tr, nn.train.scaled))
nn.test.scaled = data.frame(cbind(dow.te, nn.test.scaled))
nn.pre2 = nn.test.scaled %>% data.frame()
nn.pre2[, 9:ncol(nn.pre2)] = NA
s1=Sys.time()
for (i in (agg)){
  print('started')
  colind = which(names(as.data.frame(nn.train.scaled))==paste0('ROH',i))
  this.train = nn.train.scaled[, c(1:8, colind)] 
  print('scaled')
  nn.model = neuralnet(ROH0~., this.train, linear.output=T, stepmax = 1e+06)
  print(paste0(i, 'modeled'))
  this.test = nn.test.scaled[, c(1:8, colind:ncol(nn.test.scaled))] %>% as.data.frame()
  print(paste0(i, 'forecasted'))
  nn.pre2[, colind] = predict(nn.model, this.test) 
}
time.nn = Sys.time() - s1

nn.pre2 = nn.pre2[, -(1:7)]
nn.pre2.unscaled = nn.pre2
nn.pre2.unscaled[,] = NA
for (i in 1:nrow(nn.pre2)){
  nn.pre2.unscaled[i,] = nn.pre2[i,]* (apply(test[,-2], 2, sd)) + (colMeans(test[,-2]))
}
nn.err2 = materr(nn.pre2.unscaled) %>% t() %>% 
  as.data.frame() 
```