---
title: "Pick-up method + machine learning: a proved efficient approach to forecast hotel demand "
author: "Rachel Zhang"
date: "05/24/2020"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE)
library(kableExtra)
library(tidyverse)
library(dplyr)
library(reshape2)
library(colorspace)
library(ggplot2)
library(texreg)
library(caret)
library(rpart)
library(e1071)
library(forecast)
library(neuralnet)
library(kknn)
library(dummies)
options(digits = 3)
setwd("~/Documents/Research/MLJournalPaper/Data")
```

```{r functions, include=FALSE}
convert_date = function(x){ #to convert date
  require(dplyr)
  new = as.Date(x, '%y.%m.%d') %>%
     format(., '20%y-%m-%d') %>%
    as.Date()
  return (new)
}

materr = function(data){  
  require(dplyr)
  m = data 
  for (j in 2:ncol(data)){
    m[,j] = (data[,j] - data[,1]) #calculating errors for each forecast
  }
  ME = colMeans(m)
  MAE = colMeans(abs(m))
  SD = apply(m,2,sd)
  p = data
  for (i in 2:ncol(p)){
    p[, i] = m[,i] / data[,1]
  }
  MPE = colMeans(p)
  MAPE = colMeans(abs(p))
  return(rbind(ME,MAE,MPE,MAPE,SD))
} 
```

# Data

## Data Importing and Cross-Validation 

```{r loaddata}
dt <- read.csv("~/Documents/Research/Thesis writing/NewData/Arr.csv") %>% 
  data.frame()%>%
  select(Arrival.Date, Booking.Window, Quantity) %>%
  mutate_at(., vars(Arrival.Date),  funs(as.Date(., "%m/%d/%Y"))) %>%
  group_by(Arrival.Date, Booking.Window) %>%
  mutate(Quan = sum(Quantity)) %>%
  dplyr::arrange(., Arrival.Date, Booking.Window, Quan) 
dt = dt[-(1:2),-3] 
dt$Arrival.Date = convert_date(dt$Arrival.Date)
#---same----# 

wide = dcast(dt, Arrival.Date ~ Booking.Window, value.var='Quan') %>% 
  data.frame() %>%
  arrange(., Arrival.Date)

for (i in (ncol(wide)-1):2){
  wide[i] = wide[i] + wide[i+1] 
}

agg = c(1, 2, 3, 4, 5, 6, 7, 14, 21, 30, 60, 90)
wide = wide %>%
  mutate(DOW = weekdays(Arrival.Date)) %>%
  remove_rownames %>% column_to_rownames('Arrival.Date') %>%
  select(X0, DOW, paste0("X",agg)) 
colnames(wide) = c('ROH0', 'DOW', paste0('ROH',agg))
wide$DOW <- ordered(wide$DOW, levels=c("Sunday","Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))

ggplot(wide, aes(x=as.Date(unlist(rownames(wide))), y=ROH0)) +
  geom_line(color='blue') +
  theme_minimal()+
  xlab("Stay Date") + ylab('Final Arrivals') +
  theme(plot.caption = element_text(hjust = 0))
```

```{r cv}
set.seed(0)
tr_ind = sample(nrow(wide), 0.8*nrow(wide))
train = wide[tr_ind, ]
test = wide[-tr_ind, ]
#-----same, data same-----
kable(train[1:10, ], 'latex', caption = 'Training Set Overview',
        longtable = F, booktabs = T) %>%
  kable_styling(latex_options = c("striped", "hold_position", "scale_down" ,"repeat_header"))
```

## Modeling
### Additive Pick-up
```{r apk}
#calculating additive pick up
apk = train    
for (j in ncol(apk):3){
  apk[,j] = apk[,1] - apk[,j]
}
apk = apk %>%
  group_by(DOW) %>%
  summarise_at(.vars=names(.)[3:ncol(apk)], .funs='mean')

apk.pre = test
apk.pre[, 3:ncol(apk.pre)] = NA

s1 = Sys.time()
for (i in 1:(nrow(apk.pre))){
  m = match(apk.pre[i,2], apk$DOW)
  apk.pre[i, 3:ncol(apk.pre)] = test[i,3:ncol(apk.pre)] + apk[m,2:ncol(apk)]
}
time.apk = Sys.time() - s1
apk.err = t(materr(apk.pre[,-2])) %>% data.frame()  
#same results#

kable(apk, 'latex', caption = 'Additive Pick Ups',
        longtable = F, booktabs = T) %>%
  kable_styling(latex_options = c("striped", "hold_position", "scale_down" ,"repeat_header"))
```

### Multiplicative Pick-up
```{r mpk}
mpk = train    
for (j in ncol(mpk):3){
  mpk[,j] = mpk[,j] / mpk[,1] 
}
mpk = mpk %>%
  group_by(DOW) %>%
  summarise_at(.vars=names(.)[3:ncol(mpk)], .funs='mean')

mpk.pre = test
mpk.pre[, 3:ncol(mpk.pre)] = NA

s1 = Sys.time()
for (i in 1:(nrow(mpk.pre))){
  m = match(mpk.pre[i,2], mpk$DOW)
  mpk.pre[i,3:ncol(mpk.pre)] = 
    test[i,3:ncol(mpk.pre)] / mpk[m, 2:ncol(mpk)]
}
time.mpk = Sys.time() - s1

mpk.err = t(materr(mpk.pre[,-2])) %>% data.frame() 
kable(mpk, 'latex', caption = 'Multiplicative Pick Ups',
        longtable = F, booktabs = T) %>%
  kable_styling(latex_options = c("striped", "hold_position", "scale_down" ,"repeat_header"))
```

### Regression 

```{r reg, results="asis"}
reg.pred = test
reg.pred[,3:ncol(reg.pred)] = NA
reg = vector(mode='list')
s1 = Sys.time()
for (i in agg){ 
  this.predictor = paste0(paste0('ROH',agg[which(agg==i)]), collapse='+')
  lm.formula = paste('ROH0', paste0('DOW+', this.predictor), sep = '~')
  reg[[this.predictor]] = lm(lm.formula, data = train)
  reg.pred[, which(names(reg.pred)==paste0('ROH',i))]=predict(reg[[this.predictor]], test)
}
time.reg = Sys.time() - s1
reg.err = t(materr(reg.pred[,-2])) %>% data.frame() 
texreg(list(reg[[1]]), table=FALSE)
            
            #, reg[[2]], reg[[3]], reg[[4]]))
            
            # , reg[[5]], reg[[6]], reg[[7]], reg[[8]],reg[[9]],reg[[10]],reg[[11]],reg[[12]]))
```


In this way, do not talk about high dimensional data - instead, how machine learning is superior - if that's the case. 

<!-- ### Neural Network -->

<!-- ```{r nn2} -->
<!-- set.seed(0) -->
<!-- nn.train.scaled=scale(train[,-2]) #standardization -->
<!-- nn.test.scaled= scale(test[,-2])  -->
<!-- dow.tr = dummy(train$DOW, sep='.') -->
<!-- dow.te = dummy(test$DOW, sep='.') -->
<!-- nn.train.scaled = data.frame(cbind(dow.tr, nn.train.scaled)) -->
<!-- nn.test.scaled = data.frame(cbind(dow.te, nn.test.scaled)) -->
<!-- nn.pre2 = nn.test.scaled %>% data.frame() -->
<!-- nn.pre2[, 9:ncol(nn.pre2)] = NA -->
<!-- #nn.err2 = read.csv('nn.err2.csv') -->
<!-- ``` -->

<!-- ```{r} -->
<!-- s1=Sys.time() -->
<!-- for (i in (agg)){ -->
<!--   colind = which(names(as.data.frame(nn.train.scaled))==paste0('ROH',i)) -->
<!--   this.train = nn.train.scaled[, c(1:8, colind)] -->
<!--   nn.model = neuralnet(ROH0~., this.train, linear.output=T, stepmax = 1e+06) -->
<!--   this.test = nn.test.scaled[, c(1:8, colind:ncol(nn.test.scaled))] %>% as.data.frame() -->
<!--   nn.pre2[, colind] = predict(nn.model, this.test)  -->
<!-- } -->
<!-- time.nn = Sys.time() - s1 -->

<!-- nn.pre2 = nn.pre2[, -(1:7)] -->
<!-- nn.pre2.unscaled = nn.pre2 -->
<!-- nn.pre2.unscaled[,] = NA -->
<!-- for (i in 1:nrow(nn.pre2)){ -->
<!--   nn.pre2.unscaled[i,] = nn.pre2[i,]* (apply(test[,-2], 2, sd)) + (colMeans(test[,-2])) -->
<!-- } -->
<!-- nn.err2 = materr(nn.pre2.unscaled) %>% t() %>%  -->
<!--   as.data.frame()  -->
<!-- ``` -->

<!-- ### K-Nearest Neighbor -->
<!-- ```{r knn2} -->
<!-- set.seed(0) -->
<!-- k.train = cbind(dow.tr, train[,-2]) -->
<!-- k.test = cbind(dow.te, test[,-2])  -->
<!-- knn.pre2 = test[,-2] -->
<!-- knn.pre2[,2:ncol(knn.pre2)]=NA -->
<!-- opk= rep(NA, length(agg)) -->
<!-- s1=Sys.time() -->
<!-- for (i in agg){ -->
<!--   colind = which(names(k.train)==paste0('ROH',i)) -->
<!--   this.train = k.train[, c(1:8, colind)] -->
<!--   train.control = trainControl(method='repeatedcv', number=10, preProcOptions = list(thresh=0.8)) #for PCA -->
<!--   k = train(ROH0~., method='knn', tuneLength = 5,  -->
<!--             trControl=train.control, preProcess=c('scale','center','pca'), -->
<!--             data=this.train) -->
<!--   opk[colind-8] = k$bestTune[[1]] -->
<!--   this.test = k.test -->
<!--   knn.pre2[,colind-7] = predict(k, this.test) -->
<!-- } -->
<!-- time.knn = Sys.time() - s1 -->
<!-- knn.err2 = materr(knn.pre2) %>% t() %>%  -->
<!--   as.data.frame()  -->
<!-- #same results!#  -->
<!-- ``` -->

<!-- ```{r wknn2} -->
<!-- set.seed(0)  -->
<!-- wknn.pre2 = test[,-2] -->
<!-- wknn.pre2[, 2:ncol(wknn.pre2)] = NA  -->
<!-- opk2 = rep(NA, ncol(test))  -->
<!-- s1=Sys.time() -->
<!-- for (i in agg){ -->
<!--   # 2s per loop -->
<!--   colind = which(names(k.train)==paste0('ROH',i)) -->
<!--   this.train = k.train[, c(1:8, colind)] -->
<!--   train.control = trainControl(method='repeatedcv', number=10, preProcOptions = list(thresh=0.8))  -->
<!--   wk = train.kknn(ROH0~., data = this.train, kmax = 20,  -->
<!--                   kernel =  c("rectangular", "triangular", "epanechnikov", "gaussian", "rank", "optimal")) -->
<!--   opk2[colind-8] = wk$best.parameters[[2]] -->
<!-- #  kknn <- kknn(ROH0~., k=opk2[i-1], scale = ROH0, distance=2,  -->
<!-- #               train = this.train, test = this.test, -->
<!-- #               kernel = paste0(toString(wk$best.parameters[[1]]))) -->
<!--   wknn.pre2[, colind-7] = predict(wk, k.test) -->
<!-- } -->
<!-- time.wknn = Sys.time() - s1 -->
<!-- wknn.err2 = materr(wknn.pre2)%>% t() %>%  -->
<!--   as.data.frame()  -->
<!-- #same# -->
<!-- ``` -->

<!-- ### Tree -->
<!-- ```{r decision_tree2}  -->
<!-- set.seed(0) -->
<!-- dtree.pre2 = test -->
<!-- dtree.pre2[, 3:ncol(dtree.pre2)] = NA -->
<!-- s1 = Sys.time() -->
<!-- for (i in agg){    -->
<!--   colind=which(names(train)==paste0('ROH',i)) -->
<!--   this.train = train[, c(1, 2, colind)] -->
<!--   tree.model = rpart(ROH0~., data=this.train, method='anova') -->
<!--   dtree.pre2[, colind] = predict(tree.model, test) -->
<!-- } -->
<!-- time.dtree = Sys.time() - s1 -->
<!-- dtree.err2 = materr(dtree.pre2[,-2]) %>% t() %>%  -->
<!--   as.data.frame() -->
<!-- #same -->
<!-- ``` -->

<!-- ```{r rf2} -->
<!-- set.seed(0) -->
<!-- rf.pre2 = test -->
<!-- rf.pre2[, 3:ncol(test)] = NA -->

<!-- mtry.rf = rep(0, length(agg)+1) -->
<!-- s1 = Sys.time() -->
<!-- for (i in agg){ -->
<!--   colind=which(names(train)==paste0('ROH',i)) -->
<!--   this.train = train[, c(1, 2, colind)] -->
<!--   train.control=trainControl(method='repeatedcv', number=10) -->
<!--   r.tree = train(ROH0~., data = this.train, method='rf', -->
<!--                trControl=train.control, metric = 'RMSE') -->
<!--   mtry.rf[colind-2] = r.tree$bestTune -->
<!--   rf.pre2[, colind] = predict(r.tree, test, type = 'raw') -->
<!-- } -->
<!-- time.rf = Sys.time() - s1 -->
<!-- rf.err2 = materr(rf.pre2[,-2])%>% t() %>%  -->
<!--   as.data.frame()  -->
<!-- ``` -->

<!-- ### Support Vector Machine  -->
<!-- ```{r svm2} -->
<!-- set.seed(0) -->
<!-- svm.pre2 = test    -->
<!-- svm.pre2[, 3:ncol(svm.pre2)] = NA -->
<!-- totot = rep(0, length(agg)) -->

<!-- for (i in agg){ -->
<!--   colind=which(names(train)==paste0('ROH',i)) -->
<!--   this.train = train[, c(1, 2, colind)] -->
<!--   svm.model = svm(ROH0~., this.train) -->
<!--   totot[colind-2]=svm.model$tot.nSV -->
<!--   svm.pre2[, colind] = predict(svm.model, test) -->
<!-- } -->
<!-- svm.err2 = materr(svm.pre2[,-2]) %>% t() %>%  -->
<!--   as.data.frame() -->
<!-- ``` -->


<!-- ## Results  -->
<!-- ```{r results_ME2} -->
<!-- ME_ALL = cbind(apk = apk.err[-1,1], mpk=mpk.err[-1,1], -->
<!--               reg = reg.err[-1,1], nn = nn.err2[-1,1], knn = knn.err2[-1,1],  -->
<!--               wknn = wknn.err2[-1,1], dtree = dtree.err2[-1,1],   -->
<!--               rf = rf.err2[-1,1], svm = svm.err2[-1,1]) %>% -->
<!--   as.data.frame()  -->
<!-- rownames(ME_ALL) = c(paste0('DBA',agg)) -->

<!-- # MEmelt = melt(as.matrix(ME_ALL), varnames=c('DBA', 'Model')) -->
<!-- # MEmelt$DBA = factor(MEmelt$DBA,  -->
<!-- #                   levels = c(paste0('DBA', agg))) -->
<!-- # MEmelt$Model = factor(MEmelt$Model,  -->
<!-- #                       levels=c('apk','mpk','reg','nn','knn','wknn', 'dtree', 'rf','svm')) -->
<!-- #  -->
<!-- # ggplot(MEmelt, aes(x=DBA, y=value, group=Model, color=Model)) + -->
<!-- #   geom_line(aes(color=Model), size=1)+ -->
<!-- #   geom_point(aes(color=Model), size=1)+ -->
<!-- #   scale_color_brewer(palette="Paired")+ -->
<!-- #   xlab('') + ylab('Mean Errors') + ylim(-10,10) + -->
<!-- #   theme_minimal()+ -->
<!-- #   theme(axis.text.x = element_text(angle=45, vjust=0.5)) -->

<!-- ME_ALL[13,] = colMeans(ME_ALL) -->
<!-- kable(ME_ALL, 'latex', caption = 'Mean Errors', -->
<!--       booktabs = T) %>% -->
<!--   kable_styling(latex_options = c("striped", "repeat_header")) -->
<!-- ``` -->

<!-- ```{r results_MAE2} -->
<!-- MAE_ALL = cbind(apk = apk.err[-1,2], mpk=mpk.err[-1,2], -->
<!--               reg = reg.err[-1,2],  nn = nn.err2[-1,2], knn = knn.err2[-1,2],  -->
<!--               wknn = wknn.err2[-1,2], dtree = dtree.err2[-1,2],   -->
<!--               rf = rf.err2[-1,2], svm = svm.err2[-1,2]) %>% -->
<!--   as.data.frame()  -->
<!-- rownames(MAE_ALL) = c(paste0('DBA',agg)) -->
<!-- #  -->
<!-- # MAEmelt = melt(as.matrix(MAE_ALL), varnames=c('DBA', 'Model')) -->
<!-- # MAEmelt$DBA = factor(MAEmelt$DBA,  -->
<!-- #               levels = c(paste0('DBA', agg))) -->
<!-- # MAEmelt$Model = factor(MAEmelt$Model,  -->
<!-- #               levels=c('apk','mpk','reg','nn','knn','wknn', 'dtree', 'rf','svm')) -->
<!-- # ggplot(MAEmelt, aes(x=DBA, y=value, group=Model, color=Model)) + -->
<!-- #   geom_line(aes(color=Model), size=1)+ -->
<!-- #   geom_point(aes(color=Model), size=1)+ -->
<!-- #   scale_color_brewer(palette="Paired")+ -->
<!-- #   xlab('') + ylab('Mean Absolute Errors') + -->
<!-- #   theme_minimal()+ ylim(0,15)+ -->
<!-- #   theme(axis.text.x = element_text(angle=45, vjust=0.5)) -->

<!-- MAE_ALL[13,] = colMeans(MAE_ALL) -->
<!-- kable(MAE_ALL, 'latex', caption = 'Mean Absolute Errors', -->
<!--       booktabs = T) %>% -->
<!--   kable_styling(latex_options = c("striped", "repeat_header")) -->
<!-- ``` -->

<!-- ```{r results_SDE2} -->
<!-- SDE_ALL = cbind(apk = apk.err[-1,5], mpk=mpk.err[-1,5], -->
<!--               reg = reg.err[-1,5],  nn = nn.err2[-1,5], knn = knn.err2[-1,5],  -->
<!--               wknn = wknn.err2[-1,5], dtree = dtree.err2[-1,5],   -->
<!--               rf = rf.err2[-1,5], svm = svm.err2[-1,5] ) %>% -->
<!--   as.data.frame()  -->
<!-- rownames(SDE_ALL) = c(paste0('DBA',agg)) -->
<!-- #  -->
<!-- # SDEmelt = melt(as.matrix(SDE_ALL), varnames=c('DBA', 'Model')) -->
<!-- # SDEmelt$DBA = factor(SDEmelt$DBA,  -->
<!-- #               levels = c(paste0('DBA', agg))) -->
<!-- # SDEmelt$Model = factor(SDEmelt$Model,  -->
<!-- #               levels=c('apk','mpk','reg','nn','knn','wknn', 'dtree', 'rf','svm')) -->
<!-- # ggplot(SDEmelt, aes(x=DBA, y=value, group=Model, color=Model)) + -->
<!-- #   geom_line(aes(color=Model), size=1)+ -->
<!-- #   geom_point(aes(color=Model), size=1)+ -->
<!-- #   scale_color_brewer(palette="Paired")+ -->
<!-- #   xlab('') + ylab('Standard Deviations') + -->
<!-- #   theme_minimal()+ ylim(0,15)+ -->
<!-- #   theme(axis.text.x = element_text(angle=45, vjust=0.5)) -->

<!-- SDE_ALL[13,] = colMeans(SDE_ALL) -->
<!-- kable(SDE_ALL, 'latex', caption = 'Standard Deviation Errors', -->
<!--       booktabs = T) %>% -->
<!--   kable_styling(latex_options = c("striped", "repeat_header")) -->
<!-- #write.csv(cbind(MEALL, MAEALL, MPEALL, MAPEALL, SD), "ran_e1_bycutoff.csv") -->
<!-- ``` -->

<!-- ```{r results_MPE2} -->
<!-- MPE_ALL = cbind(apk = apk.err[-1,3], mpk=mpk.err[-1,3], -->
<!--               reg = reg.err[-1,3],  nn = nn.err2[-1,3], knn = knn.err2[-1,3],  -->
<!--               wknn = wknn.err2[-1,3], dtree = dtree.err2[-1,3],   -->
<!--               rf = rf.err2[-1,3], svm = svm.err2[-1,3]) %>% -->
<!--   as.data.frame()  -->
<!-- rownames(MPE_ALL) = c(paste0('DBA',agg)) -->
<!-- #  -->
<!-- # MPEmelt = melt(as.matrix(MPE_ALL), varnames=c('DBA', 'Model')) -->
<!-- # MPEmelt$DBA = factor(MPEmelt$DBA,  -->
<!-- #               levels = c(paste0('DBA', agg))) -->
<!-- # MPEmelt$Model = factor(MPEmelt$Model,  -->
<!-- #               levels=c('apk','mpk','reg','nn','knn','wknn', 'dtree', 'rf','svm')) -->
<!-- # ggplot(MPEmelt, aes(x=DBA, y=value, group=Model, color=Model)) + -->
<!-- #   geom_line(aes(color=Model), size=1)+ -->
<!-- #   geom_point(aes(color=Model), size=1)+ -->
<!-- #   scale_color_brewer(palette="Paired")+ -->
<!-- #   xlab('') + ylab('Mean Percentage Errors') + -->
<!-- #   theme_minimal()+  -->
<!-- #   theme(axis.text.x = element_text(angle=45, vjust=0.5)) -->

<!-- MPE_ALL[13,] = colMeans(MPE_ALL) -->
<!-- kable(MPE_ALL, 'latex', caption = 'Mean Percentage Errors', -->
<!--       booktabs = T) %>% -->
<!--   kable_styling(latex_options = c("striped", "repeat_header")) -->
<!-- ``` -->

<!-- ```{r results_MAPE2} -->
<!-- MAPE_ALL = cbind(apk = apk.err[-1,4], mpk=mpk.err[-1,4], -->
<!--               reg = reg.err[-1,4],  nn = nn.err2[-1,4], knn = knn.err2[-1,4], -->
<!--               wknn = wknn.err2[-1,4], dtree = dtree.err2[-1,4],   -->
<!--               rf = rf.err2[-1,4], svm = svm.err2[-1,4]) %>% -->
<!--   as.data.frame()  -->
<!-- rownames(MAPE_ALL) = c(paste0('DBA',agg)) -->

<!-- # MAPEmelt = melt(as.matrix(MAPE_ALL), varnames=c('DBA', 'Model')) -->
<!-- # MAPEmelt$DBA = factor(MAPEmelt$DBA,  -->
<!-- #               levels = c(paste0('DBA', agg))) -->
<!-- # MAPEmelt$Model = factor(MAPEmelt$Model,  -->
<!-- #               levels=c('apk','mpk','reg','nn','knn','wknn', 'dtree', 'rf','svm')) -->
<!-- # ggplot(MAPEmelt, aes(x=DBA, y=value, group=Model, color=Model)) + -->
<!-- #   geom_line(aes(color=Model), size=1)+ -->
<!-- #   geom_point(aes(color=Model), size=1)+ -->
<!-- #   scale_color_brewer(palette="Paired")+ -->
<!-- #   xlab('') + ylab('Mean Absolute Percentage Errors') + -->
<!-- #   theme_minimal()+ -->
<!-- #   theme(axis.text.x = element_text(angle=45, vjust=0.5)) -->

<!-- MAPE_ALL[13,] = colMeans(MAPE_ALL) -->
<!-- kable(MAPE_ALL, row.names = NA, 'latex', caption = 'MAPE', -->
<!--       booktabs = T) %>% -->
<!--   kable_styling(latex_options = c("striped", "repeat_header")) -->
<!-- ``` -->



