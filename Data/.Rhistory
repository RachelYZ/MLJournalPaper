for (i in agg){
colind=which(names(ran.train)==paste0('ROH',i))
this.train = ran.train[,c(1,colind:ncol(ran.train))]
train.control = trainControl(method='repeatedcv', number=10)
wk = train.kknn(ROH0~., data = this.train, kmax = 10,
kernel =  c("rectangular", "triangular", "epanechnikov", "gaussian", "rank", "optimal"))
opk[, colind] = wk$best.parameters[[2]]
this.test = ran.test
ran.wknn.pre[, colind] = predict(wk, this.test)
}
for (i in agg){
#each loop takes 1min
colind = which(names(ran.train)==paste0('ROH',i))
this.train = ran.train[, c(1, colind:ncol(ran.train))]
train.control = trainControl(method='repeatedcv', number=10)
k = train(ROH0~., method='knn', tuneLength = 10,
trControl=train.control, preProcess=c('scale','center'),
data=this.train)
opk[, colind] = k$bestTune[[1]]
this.test = ran.test
ran.knn.pre[,colind] = predict(k, this.test)
print(Sys.time()-s1)
}
set.seed(0)
ran.wknn.pre = ran.test
ran.wknn.pre[, 2:ncol(ran.wknn.pre)] = NA
opk2 = rep(NA, ncol(ran.test))
for (i in agg){
colind=which(names(ran.train)==paste0('ROH',i))
this.train = ran.train[,c(1,colind:ncol(ran.train))]
train.control = trainControl(method='repeatedcv', number=10)
wk = train.kknn(ROH0~., data = this.train, kmax = 10,
kernel =  c("rectangular", "triangular", "epanechnikov", "gaussian", "rank", "optimal"))
opk2[, colind] = wk$best.parameters[[2]]
this.test = ran.test
ran.wknn.pre[, colind] = predict(wk, this.test)
}
i=60
colind=which(names(ran.train)==paste0('ROH',i))
this.train = ran.train[,c(1,colind:ncol(ran.train))]
train.control = trainControl(method='repeatedcv', number=10)
wk = train.kknn(ROH0~., data = this.train, kmax = 10,
kernel =  c("rectangular", "triangular", "epanechnikov", "gaussian", "rank", "optimal"))
opk2[, colind] = wk$best.parameters[[2]]
wk$best.parameters[[2]]
opk2
opk2[colind] = wk$best.parameters[[2]]
for (i in agg){
colind=which(names(ran.train)==paste0('ROH',i))
this.train = ran.train[,c(1,colind:ncol(ran.train))]
train.control = trainControl(method='repeatedcv', number=10)
wk = train.kknn(ROH0~., data = this.train, kmax = 10,
kernel =  c("rectangular", "triangular", "epanechnikov", "gaussian", "rank", "optimal"))
opk2[colind] = wk$best.parameters[[2]]
this.test = ran.test
ran.wknn.pre[, colind] = predict(wk, this.test)
}
ran.wknn.err = materr(ran.wknn.pre)%>% t() %>%
as.data.frame()
opk2
i=1
colind=which(names(ran.train)==paste0('ROH',i))
colind
set.seed(0)
ran.wknn.pre = ran.test
ran.wknn.pre[, 2:ncol(ran.wknn.pre)] = NA
opk2 = opk= ran.test[1,]
for (i in agg){
colind=which(names(ran.train)==paste0('ROH',i))
this.train = ran.train[,c(1,colind:ncol(ran.train))]
train.control = trainControl(method='repeatedcv', number=10)
wk = train.kknn(ROH0~., data = this.train, kmax = 10,
kernel =  c("rectangular", "triangular", "epanechnikov", "gaussian", "rank", "optimal"))
opk2[colind] = wk$best.parameters[[2]]
this.test = ran.test
ran.wknn.pre[, colind] = predict(wk, this.test)
}
opk2
opk2 = ran.test[1,]
for (i in agg){
colind=which(names(ran.train)==paste0('ROH',i))
this.train = ran.train[,c(1,colind:ncol(ran.train))]
train.control = trainControl(method='repeatedcv', number=10)
wk = train.kknn(ROH0~., data = this.train, kmax = 10,
kernel =  c("rectangular", "triangular", "epanechnikov", "gaussian", "rank", "optimal"))
opk2[colind] = wk$best.parameters[[2]]
this.test = ran.test
ran.wknn.pre[, colind] = predict(wk, this.test)
}
opk2
opk
set.seed(0)
train.true = ran.train[,1]
ran.knn.pre = ran.test
ran.knn.pre[,2:ncol(ran.knn.pre)]=NA
opk= ran.test[1,]
s1 = Sys.time()
for (i in agg){
#each loop takes 1min
colind = which(names(ran.train)==paste0('ROH',i))
this.train = ran.train[, c(1, colind:ncol(ran.train))]
train.control = trainControl(method='repeatedcv', number=10)
k = train(ROH0~., method='knn', tuneLength = 10,
trControl=train.control, preProcess=c('scale','center'),
data=this.train)
opk[, colind] = k$bestTune[[1]]
this.test = ran.test
ran.knn.pre[,colind] = predict(k, this.test)
print(Sys.time()-s1)
}
opk
ran.dtree.pred = ran.test
ran.dtree.pred
ran.dtree.pred[,2:ncol(ran.dtree.pred)] = NA
i=6-
i=60
colind=which(names(ran.train)==paste0('ROH',i))
colind
this.train = ran.train[, c(1, colind:ncol(ran.train))]
tree.model = rpart(ROH0~., data=this.train, method='anova')
library(tree)
library(rpart)
tree.model = rpart(ROH0~., data=this.train, method='anova')
this.test = ran.test
ran.dtree.pred[, colind] = predict(tree.model, this.test)
for (i in agg){
colind=which(names(ran.train)==paste0('ROH',i))
this.train = ran.train[, c(1, colind:ncol(ran.train))]
tree.model = rpart(ROH0~., data=this.train, method='anova')
this.test = ran.test
ran.dtree.pred[, colind] = predict(tree.model, this.test)
}
ran.dtree.pred
ran.dtree.err = materr(ran.dtree.pred[,-2]) %>% t() %>%
as.data.frame()
set.seed(0)
ran.rf.pred = ran.test
ran.rf.pred[, 2:ncol(ran.test)] = NA
ran.rf.pred
i
i=6-
i=60
this.train = ran.train[,c(1, colind:ncol(ran.train))]
this.test = ran.test
train.control=trainControl(method='repeatedcv', number=10, search='random')
#  rtt = randomForest(ROH0~., data = this.train)
r.tree = train(ROH0~., data = this.train, method='rf',
trControl=train.control, tuneLength = 10)
ran.rf.pred
#print(r.tree)
ran.rf.pred[, colind] = predict(r.tree, this.test, type = 'raw')
set.seed(0)
ran.rf.pred = ran.test
ran.rf.pred[, 2:ncol(ran.test)] = NA
s1 = Sys.time()
for (i in agg){
colind=which(names(ran.train)==paste0('ROH',i))
this.train = ran.train[,c(1, colind:ncol(ran.train))]
this.test = ran.test
train.control=trainControl(method='repeatedcv', number=10, search='random')
#  rtt = randomForest(ROH0~., data = this.train)
r.tree = train(ROH0~., data = this.train, method='rf',
trControl=train.control, tuneLength = 10)
print(Sys.time()-s1)
#print(r.tree)
ran.rf.pred[, colind] = predict(r.tree, this.test, type = 'raw')
}
ran.dtree.err
ran.dtree.pred
ran.svm.pred = ran.test
ran.svm.pred[,2:ncol(ran.svm.pred)] = NA
i=60
colind=which(names(ran.train)==paste0('ROH',i))
colind
this.train = ran.train[, c(1, colind:ncol(this.train))]
this.train
ncol(this.train)
this.train = ran.train[, c(1, colind:ncol(ran.train))]
this.train
svm.model = svm(ROH0~., this.train)
library(svm)
??svm
library(e1071)
svm.model = svm(ROH0~., this.train)
totot
totot = rep(0, 90)
svm.model
svm.model$tot.nSV
length(agg)
support_vector_number = rep(NA, length(agg))
support_vector_number = rep(NA, length(agg)+1)
support_vector_number[colind]=svm.model$tot.nSV
support_vector_number
this.test = ran.test
ran.svm.pred[, colind] = predict(svm.model, this.test)
ran.svm.pred
set.seed(0)
ran.svm.pred = ran.test
ran.svm.pred[,2:ncol(ran.svm.pred)] = NA
support_vector_number = rep(NA, length(agg)+1)
for (i in agg){
colind=which(names(ran.train)==paste0('ROH',i))
this.train = ran.train[, c(1, colind:ncol(ran.train))]
svm.model = svm(ROH0~., this.train)
support_vector_number[colind]=svm.model$tot.nSV
ran.svm.pred[, colind] = predict(svm.model, ran.test)
}
ran.svm.pred
ran.svm.err = materr(ran.svm.pred[,-2]) %>% t() %>%
as.data.frame()
ran.svm.err
support_vector_number
?svm
ran.svm.err1 = materr(ran.svm.pred[,-2]) %>% t() %>%
as.data.frame()
ran.svm.pred
i
i=60
colind=which(names(ran.train)==paste0('ROH',i))
this.train = ran.train[, c(1, colind:ncol(ran.train))]
svm.model = svm(ROH0~., this.train, kernal = 'polynomial')
support_vector_number[colind]=svm.model$tot.nSV
support_vector_number
support_vector_number = rep(NA, length(agg)+1)
colind=which(names(ran.train)==paste0('ROH',i))
this.train = ran.train[, c(1, colind:ncol(ran.train))]
svm.model = svm(ROH0~., this.train, kernal = 'polynomial')
support_vector_number[colind]=svm.model$tot.nSV
support_vector_number
set.seed(0)
ran.svm.pred = ran.test
ran.svm.pred[,2:ncol(ran.svm.pred)] = NA
support_vector_number = rep(NA, length(agg)+1)
for (i in agg){
colind=which(names(ran.train)==paste0('ROH',i))
this.train = ran.train[, c(1, colind:ncol(ran.train))]
svm.model = svm(ROH0~., this.train, kernal = 'polynomial')
support_vector_number[colind]=svm.model$tot.nSV
ran.svm.pred[, colind] = predict(svm.model, ran.test)
}
ran.svm.err.polynomial = materr(ran.svm.pred) %>% t() %>% as.data.frame()
ran.svm.err.polynomial
ran.svm.err
set.seed(0)
ran.svm.pred = ran.test
ran.svm.pred[,2:ncol(ran.svm.pred)] = NA
support_vector_number = rep(NA, length(agg)+1)
for (i in agg){
colind=which(names(ran.train)==paste0('ROH',i))
this.train = ran.train[, c(1, colind:ncol(ran.train))]
svm.model = svm(ROH0~., this.train, kernal = 'radial')
support_vector_number[colind]=svm.model$tot.nSV
ran.svm.pred[, colind] = predict(svm.model, ran.test)
}
support_vector_number
ran.svm.err.radial = materr(ran.svm.pred) %>% t() %>% as.data.frame()
ran.svm.err.radial
set.seed(0)
ran.svm.pred = ran.test
ran.svm.pred[,2:ncol(ran.svm.pred)] = NA
support_vector_number = rep(NA, length(agg)+1)
for (i in agg){
colind=which(names(ran.train)==paste0('ROH',i))
this.train = ran.train[, c(1, colind:ncol(ran.train))]
svm.model = svm(ROH0~., this.train, kernal = 'radial')
support_vector_number[colind]=svm.model$tot.nSV
ran.svm.pred[, colind] = predict(svm.model, ran.test)
}
for (i in agg){
colind=which(names(ran.train)==paste0('ROH',i))
this.train = ran.train[, c(1, colind:ncol(ran.train))]
svm.model = svm(ROH0~., this.train, kernal = 'sigmoid')
support_vector_number[colind]=svm.model$tot.nSV
ran.svm.pred[, colind] = predict(svm.model, ran.test)
}
ran.svm.err.sigmoid = materr(ran.svm.pred) %>% t() %>% as.data.frame() #no diff
ran.svm.err.sigmoid
i=5
colind=which(names(ran.train)==paste0('ROH',i))
this.train = ran.train[, c(1, colind:ncol(ran.train))]
colind=which(names(ran.train)==paste0('ROH',i))
this.train = ran.train[, c(1, colind:ncol(ran.train))]
optmodelsvm = tune(svm, ROH0~., data = this.train,
ranges=list(elsilon=seq(0,1,0.1), cost=1:100))
optmodelsvm = tune(svm, ROH0~., data = this.train,
ranges=list(elsilon=seq(0,1,0.1), cost=1:10))
optmodelsvm
svm.mode = optmodelsvm$best.model
ran.svm.pred[, colind] = predict(svm.model, ran.test)
ran.svm.pred
ran.svm.pred[,2:ncol(ran.svm.pred)] = NA
ran.svm.pred[, colind] = predict(svm.model, ran.test)
ran.svm.pred
optmodelsvm$best.parameters
svm.model = optmodelsvm$best.model
ran.svm.pred[, colind] = predict(svm.model, ran.test)
ran.svm.pred
i=4
colind=which(names(ran.train)==paste0('ROH',i))
this.train = ran.train[, c(1, colind:ncol(ran.train))]
optmodelsvm = tune(svm, ROH0~., data = this.train,
ranges=list(elsilon=seq(0,1,0.1), cost=1:5))
#  svm.model = svm(ROH0~., data = this.train)
#  support_vector_number[colind]=svm.model$tot.nSV
svm.model = optmodelsvm$best.model
ran.svm.pred[, colind] = predict(svm.model, ran.test)
ran.svm.pred
ran.svm.err
ran.svm.pred = ran.test
ran.svm.pred[,2:ncol(ran.svm.pred)] = NA
for (i in agg){
colind=which(names(ran.train)==paste0('ROH',i))
this.train = ran.train[, c(1, colind:ncol(ran.train))]
optmodelsvm = tune(svm, ROH0~., data = this.train,
ranges=list(elsilon=seq(0,1,0.1), cost=1:5))
#  svm.model = svm(ROH0~., data = this.train)
#  support_vector_number[colind]=svm.model$tot.nSV
svm.model = optmodelsvm$best.model
ran.svm.pred[, colind] = predict(svm.model, ran.test)
}
s1=Sys.time()
for (i in agg){
colind=which(names(ran.train)==paste0('ROH',i))
this.train = ran.train[, c(1, colind:ncol(ran.train))]
optmodelsvm = tune(svm, ROH0~., data = this.train,
ranges=list(elsilon=seq(0,1,0.1), cost=1:5))
#  svm.model = svm(ROH0~., data = this.train)
#  support_vector_number[colind]=svm.model$tot.nSV
svm.model = optmodelsvm$best.model
ran.svm.pred[, colind] = predict(svm.model, ran.test)
print(Sys.time()-s1)
}
#ran.svm.err
ran.svm.err.tuned = materr(ran.svm.pred) %>% t() %>% as.data.frame()
cbind(ran.svm.err, ran.svm.err.tuned)
ran.svm.err.tuned
ran.svm.err
ran.apk.err
ran.reg.err
ran.nn.err
ran.nn.pred.unscaled
ran.nn.err = materr(ran.nn.pred.unscaled) %>% t() %>%
as.data.frame()
ran.nn.err
e2_SDE_ALL = cbind(apk = ran.apk.err[-1,5], mpk=ran.mpk.err[-1,5],
reg = ran.reg.err[-1,5],  nn = ran.nn.err[-1,5],knn = ran.knn.err[-1,5],
wknn = ran.wknn.err[-1,5], dtree = ran.dtree.err[-1,5],
rf = ran.rf.err[-1,5], svm = ran.svm.err[-1,5] ) %>%
as.data.frame()
install.packages("gtrendsR")
library(gtrendsR)
library(gtrendsR)
library(tidyverse)
library(anomalize)
install.packages("anomalize")
install.packages("anomalize")
install.packages("anomalize")
install.packages("anomalize")
install.packages("anomalize")
install.packages("anomalize")
install.packages("anomalize")
today+5-y
#create df with google trends data
google_trends_df = gtrends(
c("Vote"), #keywords -- start with one
gprop = "web", #choose: web, news, images, froogle, youtube
geo = c("US"), #only pull results for US
time = "today+5-y")[[1]] #timeframe
library(gtrendsR)
library(tidyverse)
library(anomalize)
install.packages("anomalize")
library(gtrendsR)
library(tidyverse)
library(anomalize)
library(tidyverse)
?rlang
install.packages(c("backports", "BH", "boot", "broom", "callr", "car", "carData", "caret", "caTools", "checkmate", "class", "cli", "clipr", "cluster", "coin", "crosstalk", "curl", "data.table", "DBI", "dbplyr", "Deriv", "devtools", "digest", "dplyr", "DT", "e1071", "ellipsis", "fansi", "fma", "forcats", "foreach", "forecast", "fracdiff", "fs", "gdtools", "GGally", "ggfortify", "ggplot2", "gh", "glue", "gplots", "gtools", "haven", "hexbin", "Hmisc", "hms", "hrbrthemes", "htmltools", "htmlwidgets", "httpuv", "httr", "igraph", "iterators", "jsonlite", "jtools", "KernSmooth", "knitr", "later", "lattice", "latticeExtra", "lava", "libcoin", "lme4", "lmerTest", "lubridate", "maptools", "markdown", "MASS", "Matrix", "matrixStats", "mgcv", "mime", "ModelMetrics", "modelr", "modeltools", "multcomp", "mvtnorm", "nlme", "nloptr", "nnet", "openssl", "openxlsx", "party", "pbkrtest", "pillar", "pkgbuild", "pkgconfig", "plotly", "plotrix", "plyr", "prettyunits", "processx", "prodlim", "promises", "ps", "purrr", "quadprog", "quantmod", "quantreg", "R6", "Rcpp", "RcppArmadillo", "RcppEigen", "recipes", "remotes", "reshape2", "rmarkdown", "roxygen2", "rpart.plot", "rstudioapi", "Rttf2pt1", "rvest", "scales", "selectr", "shiny", "sp", "SparseM", "spatial", "SQUAREM", "stringi", "strucchange", "survival", "sys", "systemfonts", "testthat", "tibble", "tidyselect", "tidyverse", "tinytex", "TTR", "usethis", "webshot", "whisker", "withr", "xfun", "xml2", "xts", "yaml", "zip", "zoo"))
install.packages(c("backports", "BH", "boot", "broom", "callr", "car", "carData", "caret", "caTools", "checkmate", "class", "cli", "clipr", "cluster", "coin", "crosstalk", "curl", "data.table", "DBI", "dbplyr", "Deriv", "devtools", "digest", "dplyr", "DT", "e1071", "ellipsis", "fansi", "fma", "forcats", "foreach", "forecast", "fracdiff", "fs", "gdtools", "GGally", "ggfortify", "ggplot2", "gh", "glue", "gplots", "gtools", "haven", "hexbin", "Hmisc", "hms", "hrbrthemes", "htmltools", "htmlwidgets", "httpuv", "httr", "igraph", "iterators", "jsonlite", "jtools", "KernSmooth", "knitr", "later", "lattice", "latticeExtra", "lava", "libcoin", "lme4", "lmerTest", "lubridate", "maptools", "markdown", "MASS", "Matrix", "matrixStats", "mgcv", "mime", "ModelMetrics", "modelr", "modeltools", "multcomp", "mvtnorm", "nlme", "nloptr", "nnet", "openssl", "openxlsx", "party", "pbkrtest", "pillar", "pkgbuild", "pkgconfig", "plotly", "plotrix", "plyr", "prettyunits", "processx", "prodlim", "promises", "ps", "purrr", "quadprog", "quantmod", "quantreg", "R6", "Rcpp", "RcppArmadillo", "RcppEigen", "recipes", "remotes", "reshape2", "rmarkdown", "roxygen2", "rpart.plot", "rstudioapi", "Rttf2pt1", "rvest", "scales", "selectr", "shiny", "sp", "SparseM", "spatial", "SQUAREM", "stringi", "strucchange", "survival", "sys", "systemfonts", "testthat", "tibble", "tidyselect", "tidyverse", "tinytex", "TTR", "usethis", "webshot", "whisker", "withr", "xfun", "xml2", "xts", "yaml", "zip", "zoo"))
install.packages(c("backports", "BH", "boot", "broom", "callr", "car", "carData", "caret", "caTools", "checkmate", "class", "cli", "clipr", "cluster", "coin", "crosstalk", "curl", "data.table", "DBI", "dbplyr", "Deriv", "devtools", "digest", "dplyr", "DT", "e1071", "ellipsis", "fansi", "fma", "forcats", "foreach", "forecast", "fracdiff", "fs", "gdtools", "GGally", "ggfortify", "ggplot2", "gh", "glue", "gplots", "gtools", "haven", "hexbin", "Hmisc", "hms", "hrbrthemes", "htmltools", "htmlwidgets", "httpuv", "httr", "igraph", "iterators", "jsonlite", "jtools", "KernSmooth", "knitr", "later", "lattice", "latticeExtra", "lava", "libcoin", "lme4", "lmerTest", "lubridate", "maptools", "markdown", "MASS", "Matrix", "matrixStats", "mgcv", "mime", "ModelMetrics", "modelr", "modeltools", "multcomp", "mvtnorm", "nlme", "nloptr", "nnet", "openssl", "openxlsx", "party", "pbkrtest", "pillar", "pkgbuild", "pkgconfig", "plotly", "plotrix", "plyr", "prettyunits", "processx", "prodlim", "promises", "ps", "purrr", "quadprog", "quantmod", "quantreg", "R6", "Rcpp", "RcppArmadillo", "RcppEigen", "recipes", "remotes", "reshape2", "rmarkdown", "roxygen2", "rpart.plot", "rstudioapi", "Rttf2pt1", "rvest", "scales", "selectr", "shiny", "sp", "SparseM", "spatial", "SQUAREM", "stringi", "strucchange", "survival", "sys", "systemfonts", "testthat", "tibble", "tidyselect", "tidyverse", "tinytex", "TTR", "usethis", "webshot", "whisker", "withr", "xfun", "xml2", "xts", "yaml", "zip", "zoo"))
install.packages(c("backports", "BH", "boot", "broom", "callr", "car", "carData", "caret", "caTools", "checkmate", "class", "cli", "clipr", "cluster", "coin", "crosstalk", "curl", "data.table", "DBI", "dbplyr", "Deriv", "devtools", "digest", "dplyr", "DT", "e1071", "ellipsis", "fansi", "fma", "forcats", "foreach", "forecast", "fracdiff", "fs", "gdtools", "GGally", "ggfortify", "ggplot2", "gh", "glue", "gplots", "gtools", "haven", "hexbin", "Hmisc", "hms", "hrbrthemes", "htmltools", "htmlwidgets", "httpuv", "httr", "igraph", "iterators", "jsonlite", "jtools", "KernSmooth", "knitr", "later", "lattice", "latticeExtra", "lava", "libcoin", "lme4", "lmerTest", "lubridate", "maptools", "markdown", "MASS", "Matrix", "matrixStats", "mgcv", "mime", "ModelMetrics", "modelr", "modeltools", "multcomp", "mvtnorm", "nlme", "nloptr", "nnet", "openssl", "openxlsx", "party", "pbkrtest", "pillar", "pkgbuild", "pkgconfig", "plotly", "plotrix", "plyr", "prettyunits", "processx", "prodlim", "promises", "ps", "purrr", "quadprog", "quantmod", "quantreg", "R6", "Rcpp", "RcppArmadillo", "RcppEigen", "recipes", "remotes", "reshape2", "rmarkdown", "roxygen2", "rpart.plot", "rstudioapi", "Rttf2pt1", "rvest", "scales", "selectr", "shiny", "sp", "SparseM", "spatial", "SQUAREM", "stringi", "strucchange", "survival", "sys", "systemfonts", "testthat", "tibble", "tidyselect", "tidyverse", "tinytex", "TTR", "usethis", "webshot", "whisker", "withr", "xfun", "xml2", "xts", "yaml", "zip", "zoo"))
install.packages(c("backports", "BH", "boot", "broom", "callr", "car", "carData", "caret", "caTools", "checkmate", "class", "cli", "clipr", "cluster", "coin", "crosstalk", "curl", "data.table", "DBI", "dbplyr", "Deriv", "devtools", "digest", "dplyr", "DT", "e1071", "ellipsis", "fansi", "fma", "forcats", "foreach", "forecast", "fracdiff", "fs", "gdtools", "GGally", "ggfortify", "ggplot2", "gh", "glue", "gplots", "gtools", "haven", "hexbin", "Hmisc", "hms", "hrbrthemes", "htmltools", "htmlwidgets", "httpuv", "httr", "igraph", "iterators", "jsonlite", "jtools", "KernSmooth", "knitr", "later", "lattice", "latticeExtra", "lava", "libcoin", "lme4", "lmerTest", "lubridate", "maptools", "markdown", "MASS", "Matrix", "matrixStats", "mgcv", "mime", "ModelMetrics", "modelr", "modeltools", "multcomp", "mvtnorm", "nlme", "nloptr", "nnet", "openssl", "openxlsx", "party", "pbkrtest", "pillar", "pkgbuild", "pkgconfig", "plotly", "plotrix", "plyr", "prettyunits", "processx", "prodlim", "promises", "ps", "purrr", "quadprog", "quantmod", "quantreg", "R6", "Rcpp", "RcppArmadillo", "RcppEigen", "recipes", "remotes", "reshape2", "rmarkdown", "roxygen2", "rpart.plot", "rstudioapi", "Rttf2pt1", "rvest", "scales", "selectr", "shiny", "sp", "SparseM", "spatial", "SQUAREM", "stringi", "strucchange", "survival", "sys", "systemfonts", "testthat", "tibble", "tidyselect", "tidyverse", "tinytex", "TTR", "usethis", "webshot", "whisker", "withr", "xfun", "xml2", "xts", "yaml", "zip", "zoo"))
install.packages(c("backports", "BH", "boot", "broom", "callr", "car", "carData", "caret", "caTools", "checkmate", "class", "cli", "clipr", "cluster", "coin", "crosstalk", "curl", "data.table", "DBI", "dbplyr", "Deriv", "devtools", "digest", "dplyr", "DT", "e1071", "ellipsis", "fansi", "fma", "forcats", "foreach", "forecast", "fracdiff", "fs", "gdtools", "GGally", "ggfortify", "ggplot2", "gh", "glue", "gplots", "gtools", "haven", "hexbin", "Hmisc", "hms", "hrbrthemes", "htmltools", "htmlwidgets", "httpuv", "httr", "igraph", "iterators", "jsonlite", "jtools", "KernSmooth", "knitr", "later", "lattice", "latticeExtra", "lava", "libcoin", "lme4", "lmerTest", "lubridate", "maptools", "markdown", "MASS", "Matrix", "matrixStats", "mgcv", "mime", "ModelMetrics", "modelr", "modeltools", "multcomp", "mvtnorm", "nlme", "nloptr", "nnet", "openssl", "openxlsx", "party", "pbkrtest", "pillar", "pkgbuild", "pkgconfig", "plotly", "plotrix", "plyr", "prettyunits", "processx", "prodlim", "promises", "ps", "purrr", "quadprog", "quantmod", "quantreg", "R6", "Rcpp", "RcppArmadillo", "RcppEigen", "recipes", "remotes", "reshape2", "rmarkdown", "roxygen2", "rpart.plot", "rstudioapi", "Rttf2pt1", "rvest", "scales", "selectr", "shiny", "sp", "SparseM", "spatial", "SQUAREM", "stringi", "strucchange", "survival", "sys", "systemfonts", "testthat", "tibble", "tidyselect", "tidyverse", "tinytex", "TTR", "usethis", "webshot", "whisker", "withr", "xfun", "xml2", "xts", "yaml", "zip", "zoo"))
library("rlang", lib.loc="/Library/Frameworks/R.framework/Versions/3.6/Resources/library")
library(tidyverse)
library(gtrendsR)
library(tidyverse)
library(anomalize)
#create df with google trends data
google_trends_df = gtrends(
c("Vote"), #keywords -- start with one
gprop = "web", #choose: web, news, images, froogle, youtube
geo = c("US"), #only pull results for US
time = "today+5-y")[[1]] #timeframe
#visualize with ggplot (optional but useful if you're choosing between keywords)
ggplot(data=google_trends_df,
aes(x=date, y=hits, group=keyword, col=keyword)) +
geom_line() +
theme_bw() +
labs(title = "Google Trends Data",
subtitle="United States search volume",
x="Time", y="Relative Interest")
#create df with google trends data
google_trends_df = gtrends(
c("hotel"), #keywords -- start with one
gprop = "web", #choose: web, news, images, froogle, youtube
geo = c("US"), #only pull results for US
time = "today+5-y")[[1]] #timeframe
#visualize with ggplot (optional but useful if you're choosing between keywords)
ggplot(data=google_trends_df,
aes(x=date, y=hits, group=keyword, col=keyword)) +
geom_line() +
theme_bw() +
labs(title = "Google Trends Data",
subtitle="United States search volume",
x="Time", y="Relative Interest")
#create df with google trends data
google_trends_df = gtrends(
c("corona"), #keywords -- start with one
gprop = "web", #choose: web, news, images, froogle, youtube
geo = c("US"), #only pull results for US
time = "today+5-y")[[1]] #timeframe
#visualize with ggplot (optional but useful if you're choosing between keywords)
ggplot(data=google_trends_df,
aes(x=date, y=hits, group=keyword, col=keyword)) +
geom_line() +
theme_bw() +
labs(title = "Google Trends Data",
subtitle="United States search volume",
x="Time", y="Relative Interest")
c("corona"), #keywords -- start with one
gprop = "web", #choose: web, news, images, froogle, youtube
geo = c("US"), #only pull results for US
time = "today+5-m")[[1]] #timeframe
#create df with google trends data
google_trends_df = gtrends(
c("corona"), #keywords -- start with one
gprop = "web", #choose: web, news, images, froogle, youtube
geo = c("US"), #only pull results for US
time = "today+5-m")[[1]] #timeframe
c("corona"), #keywords -- start with one
gprop = "web", #choose: web, news, images, froogle, youtube
geo = c("US"), #only pull results for US
time = "today+5-month")[[1]] #timeframe
#create df with google trends data
google_trends_df = gtrends(
c("corona"), #keywords -- start with one
gprop = "web", #choose: web, news, images, froogle, youtube
geo = c("US"), #only pull results for US
time = "today+5-month")[[1]] #timeframe
#create df with google trends data
google_trends_df = gtrends(
c("travel"), #keywords -- start with one
gprop = "web", #choose: web, news, images, froogle, youtube
geo = c("US"), #only pull results for US
time = "today+5-y")[[1]] #timeframe
#visualize with ggplot (optional but useful if you're choosing between keywords)
ggplot(data=google_trends_df,
aes(x=date, y=hits, group=keyword, col=keyword)) +
geom_line() +
theme_bw() +
labs(title = "Google Trends Data",
subtitle="United States search volume",
x="Time", y="Relative Interest")
#prepare data
google_trends_df_tbl = google_trends_df %>%
mutate(date=lubridate::ymd(date)) %>%
tbl_df()
# Twitter and GESD
google_trends_df_tbl %>%
time_decompose(hits, method = "twitter",trend = "1 month") %>%
anomalize(remainder, method = "gesd") %>%
time_recompose() %>%
# Anomaly Visualization
plot_anomalies(time_recomposed = TRUE) +
labs(title = "Google Trends Data - Twitter + GESD Method",x="Time",y="Relative Interest", subtitle = "United States search volume for 'Travel' in the last 5 years"
)
#create df with google trends data
google_trends_df = gtrends(
c("warren"), #keywords -- start with one
gprop = "web", #choose: web, news, images, froogle, youtube
geo = c("US"), #only pull results for US
time = "today+5-y")[[1]] #timeframe
#visualize with ggplot (optional but useful if you're choosing between keywords)
ggplot(data=google_trends_df,
aes(x=date, y=hits, group=keyword, col=keyword)) +
geom_line() +
theme_bw() +
labs(title = "Google Trends Data",
subtitle="United States search volume",
x="Time", y="Relative Interest")
ggplot(wide, aes(x=as.Date(unlist(rownames(wide))), y=ROH0)) +
geom_line() +
theme_minimal()+
xlab("Stay Date") + ylab('Final Arrivals') +
theme(plot.caption = element_text(hjust = 0))
library(kableExtra)
library(tidyverse)
library(dplyr)
library(reshape2)
library(colorspace)
library(ggplot2)
library(texreg)
library(caret)
library(rpart)
library(e1071)
library(forecast)
options(digits = 3)
library(neuralnet)
library(kknn)
?rfe
?caret::train
